# 2018.10.04 Deep learning practice_5

1. Azért szoktuk keras-ban külön rétegbe rakni az aktivációt, hogy a réteg és az aktiváció közé más dolgokat is be tudjunk tenni.
2. Ha nem skálázzuk megfelelően az adatot, akkor az utsó/kimeneti rétegnek lehet lineáris aktivációs függvényt választani --> nem szép!, de lehet
3. K-fold validáció --> folyamatosan csúztatjuk az adatokon, hogy mi legyen a tanító, validáció és a teszt
4. 



