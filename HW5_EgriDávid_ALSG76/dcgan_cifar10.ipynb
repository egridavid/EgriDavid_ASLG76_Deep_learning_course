{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dcgan_cifar10.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"2pSWUVF-Wadn","colab_type":"text"},"cell_type":"markdown","source":["# DL 5th HW"]},{"metadata":{"id":"15GT-fkkWfQ_","colab_type":"text"},"cell_type":"markdown","source":["source: https://medium.com/@utk.is.here/keep-calm-and-train-a-gan-pitfalls-and-tips-on-training-generative-adversarial-networks-edd529764aa9"]},{"metadata":{"id":"keFPoKqqgG9e","colab_type":"code","colab":{}},"cell_type":"code","source":["colab=True"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"_vA8knol6rGi","colab":{"base_uri":"https://localhost:8080/","height":785},"outputId":"a34094ee-b907-4cd8-d6ca-1607f082e1f9","executionInfo":{"status":"ok","timestamp":1544116537003,"user_tz":-60,"elapsed":40971,"user":{"displayName":"Martin Kovács","photoUrl":"","userId":"06420018141512010268"}}},"cell_type":"code","source":["from keras.layers import Input, Dense, Flatten, Dropout, Reshape\n","from keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.models import Model\n","from keras.optimizers import Adam\n","\n","from keras.datasets import cifar10\n","import keras.backend as K\n","\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","\n","# making sure we used the newest versions\n","!pip install --upgrade keras \n","!pip install --upgrade tensorflow\n","\n","# for data handling\n","import pandas as pd\n","from collections import defaultdict, OrderedDict\n","\n","# for path handling\n","from pathlib import Path\n","\n","# for file handling\n","import os\n","import warnings\n","\n","# Only if working from Google Colab\n","if colab:\n","    # Mount the Google Drive to reach its data\n","    from google.colab import drive\n","    drive.mount(Path(r'/content/gdrive'))\n","    # Make the Working Directory where the dataset is\n","    os.chdir(Path(r'/content/gdrive/My Drive/DL_HW5'))\n","    # making sure we used the newest versions\n","\n","# Progressbar generator\n","!pip install --force https://github.com/chengs/tqdm/archive/colab.zip\n","from tqdm import tqdm_notebook as tqdm"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n","Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.6)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.5)\n","Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n","Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (1.12.0)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.5)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.6)\n","Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n","Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.32.3)\n","Requirement already satisfied, skipping upgrade: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.6.1)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.6.1)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (0.14.1)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.0.1)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.6.2)\n","Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","Collecting https://github.com/chengs/tqdm/archive/colab.zip\n","  Downloading https://github.com/chengs/tqdm/archive/colab.zip\n","\u001b[K     \\ 512kB 585kB/s\n","Building wheels for collected packages: tqdm\n","  Running setup.py bdist_wheel for tqdm ... \u001b[?25l-\b \b\\\b \bdone\n","\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-sdug0qob/wheels/41/18/ee/d5dd158441b27965855b1bbae03fa2d8a91fe645c01b419896\n","Successfully built tqdm\n","\u001b[31mspacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n","Installing collected packages: tqdm\n","  Found existing installation: tqdm 4.28.1\n","    Uninstalling tqdm-4.28.1:\n","      Successfully uninstalled tqdm-4.28.1\n","Successfully installed tqdm-4.28.1\n"],"name":"stdout"}]},{"metadata":{"id":"CleqbPVVc9WC","colab_type":"code","colab":{}},"cell_type":"code","source":["SAVE_DIR = './cifar_10/1'\n","\n","if not os.path.exists(SAVE_DIR):\n","    os.makedirs(SAVE_DIR)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"MZRiRjRj6xO4","colab":{}},"cell_type":"code","source":["def get_generator(input_layer):\n","    '''\n","    Requires the input layer as input, outputs the model and the final layer\n","    '''\n","    hid = Dense(128 * 16 * 16, activation='relu')(input_layer)    \n","    hid = BatchNormalization(momentum=0.9)(hid)\n","    hid = LeakyReLU(alpha=0.1)(hid)\n","    hid = Reshape((16, 16, 128))(hid)\n","\n","    hid = Conv2D(128, kernel_size=5, strides=1,padding='same')(hid)\n","    hid = BatchNormalization(momentum=0.9)(hid)\n","    hid = LeakyReLU(alpha=0.1)(hid)\n","\n","    hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n","    hid = BatchNormalization(momentum=0.9)(hid)\n","    hid = LeakyReLU(alpha=0.1)(hid)\n","\n","    hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n","    hid = BatchNormalization(momentum=0.9)(hid)\n","    hid = LeakyReLU(alpha=0.1)(hid)\n","\n","    hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n","    hid = BatchNormalization(momentum=0.9)(hid)\n","    hid = LeakyReLU(alpha=0.1)(hid)\n","                       \n","    hid = Conv2D(3, kernel_size=5, strides=1, padding=\"same\")(hid)\n","    out = Activation(\"tanh\")(hid)\n","\n","    model = Model(input_layer, out)\n","    model.summary()\n","  \n","    return model, out\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"4yFseSJQ62d2","colab":{}},"cell_type":"code","source":["def get_discriminator(input_layer):\n","    '''\n","    Requires the input layer as input, outputs the model and the final layer\n","    '''\n","\n","    hid = Conv2D(128, kernel_size=3, strides=1, padding='same')(input_layer)\n","    hid = BatchNormalization(momentum=0.9)(hid)\n","    hid = LeakyReLU(alpha=0.1)(hid)\n","\n","    hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n","    hid = BatchNormalization(momentum=0.9)(hid)\n","    hid = LeakyReLU(alpha=0.1)(hid)\n","\n","    hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n","    hid = BatchNormalization(momentum=0.9)(hid)\n","    hid = LeakyReLU(alpha=0.1)(hid)\n","\n","    hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n","    hid = BatchNormalization(momentum=0.9)(hid)\n","    hid = LeakyReLU(alpha=0.1)(hid)\n","\n","    hid = Flatten()(hid)\n","    out = Dense(1, activation='sigmoid')(hid)\n","\n","    model = Model(input_layer, out)\n","\n","    model.summary()\n","\n","    return model, out"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"uFSdLdMv67Oq","colab":{}},"cell_type":"code","source":["from keras.preprocessing import image\n","\n","def generate_noise(n_samples, noise_dim):\n","    X = np.random.normal(0, 1, size=(n_samples, noise_dim))\n","    return X\n","\n","def show_imgs(epoch, savedir=None):\n","    noise = generate_noise(9, 100)\n","    gen_imgs = generator.predict(noise)\n","\n","    fig, axs = plt.subplots(3, 3)\n","    count = 0\n","    for i in range(3):\n","        for j in range(3):\n","      # Dont scale the images back, let keras handle it\n","            img = image.array_to_img(gen_imgs[count], scale=True)\n","            axs[i,j].imshow(img)\n","            axs[i,j].axis('off')\n","            count += 1\n","    fig.suptitle(\"Sample after %d epoch\" % epoch, fontsize=16)\n","    \n","    filename = (\"sample_%d.png\" % epoch)\n","    plt.savefig(os.path.join(savedir, filename))\n","    \n","    plt.show()\n","    plt.close('all')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"Iha5HiXj7FRg","colab":{"base_uri":"https://localhost:8080/","height":1632},"outputId":"8104ac79-e002-4c68-f21e-35c2742dc852","executionInfo":{"status":"ok","timestamp":1544116541075,"user_tz":-60,"elapsed":44937,"user":{"displayName":"Martin Kovács","photoUrl":"","userId":"06420018141512010268"}}},"cell_type":"code","source":["# GAN creation\n","img_input = Input(shape=(32,32,3))\n","discriminator, disc_out = get_discriminator(img_input)\n","discriminator.compile(optimizer=Adam(0.0001, 0.2), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","discriminator.trainable = False\n","\n","noise_input = Input(shape=(100,))\n","generator, gen_out = get_generator(noise_input)\n","\n","gan_input = Input(shape=(100,))\n","x = generator(gan_input)\n","gan_out = discriminator(x)\n","gan = Model(gan_input, gan_out)\n","gan.summary()\n","\n","gan.compile(optimizer=Adam(0.0001, 0.2), loss='binary_crossentropy')\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 32, 32, 128)       3584      \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 32, 32, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 16, 16, 128)       262272    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 8, 8, 128)         262272    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 4, 4, 128)         262272    \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 4, 4, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 2048)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 2049      \n","=================================================================\n","Total params: 794,497\n","Trainable params: 793,473\n","Non-trainable params: 1,024\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 100)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32768)             3309568   \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 32768)             131072    \n","_________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)    (None, 32768)             0         \n","_________________________________________________________________\n","reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 16, 16, 128)       409728    \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 16, 16, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_transpose_1 (Conv2DTr (None, 32, 32, 128)       262272    \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 32, 32, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 32, 32, 128)       409728    \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 32, 32, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)    (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 32, 32, 128)       409728    \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 32, 32, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_9 (LeakyReLU)    (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 32, 32, 3)         9603      \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 32, 32, 3)         0         \n","=================================================================\n","Total params: 4,943,747\n","Trainable params: 4,877,187\n","Non-trainable params: 66,560\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 100)               0         \n","_________________________________________________________________\n","model_2 (Model)              (None, 32, 32, 3)         4943747   \n","_________________________________________________________________\n","model_1 (Model)              (None, 1)                 794497    \n","=================================================================\n","Total params: 5,738,244\n","Trainable params: 4,877,187\n","Non-trainable params: 861,057\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"x_C473Ji7OtQ","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"78a0ca75-9300-4c21-ddec-0805a5ec3ba1","executionInfo":{"status":"ok","timestamp":1544116640513,"user_tz":-60,"elapsed":74351,"user":{"displayName":"Martin Kovács","photoUrl":"","userId":"06420018141512010268"}}},"cell_type":"code","source":["BATCH_SIZE = 128\n","\n","# # Get training images\n","(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","\n","# Select only Cats\n","X_train = X_train[y_train[:,0]==3]\n","X_test = X_test[y_test[:,0]==3]\n","print (\"Training shape: {}\".format(X_train.shape))\n","print (\"Testing shape: {}\".format(X_test.shape))\n","\n","# Normalize data\n","X_train = (X_train - 127.5) / 127.5\n","X_test = (X_test - 127.5) / 127.5\n"," \n","num_batches = int(X_train.shape[0]/BATCH_SIZE)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 70s 0us/step\n","Training shape: (5000, 32, 32, 3)\n","Testing shape: (1000, 32, 32, 3)\n"],"name":"stdout"}]},{"metadata":{"id":"e359iewQBgma","colab_type":"text"},"cell_type":"markdown","source":["# Train"]},{"metadata":{"id":"61wt-tXSBhtB","colab_type":"text"},"cell_type":"markdown","source":["Main differences between a common DCGAN that:\n","1. It uses soft labels, meaning instead of using hard labels (1 for generated image and 0 for true) it randomly generates between 0.9 and 1 for generated images and between 0 and 0.1 for true images. Only for the discriminator, because it keeps from rapidly go to 0.\n","\n","2. Flips 5% of labels to opposite labels . This is for only the discriminator. \n"]},{"metadata":{"colab_type":"code","id":"jUgkE7bW7ZNK","colab":{"base_uri":"https://localhost:8080/","height":22018,"output_embedded_package_id":"1IdUGJ0fu-OBKjS8iEnY6SHnfmNsrehqF"},"outputId":"5fee27c0-a391-4e19-b078-9d8b3a7729a4","executionInfo":{"status":"ok","timestamp":1544128950218,"user_tz":-60,"elapsed":12088380,"user":{"displayName":"Martin Kovács","photoUrl":"","userId":"06420018141512010268"}}},"cell_type":"code","source":["N_EPOCHS = 200\n","initial_epoch=1\n","SAVE_INTERVAL=5\n","logs=dict(d_loss=[],d_true_loss=[], d_gene_loss=[], g_loss=[])\n","logs_val=dict(d_val_loss=[], d_true_val_loss=[], d_gene_val_loss=[], d_true_val_acc=[], d_gene_val_acc=[])\n","\n","for epoch in tqdm(range(initial_epoch, N_EPOCHS+1)):\n","    discriminator_true_loss=[]\n","    discriminator_gene_loss=[]\n","    generator_loss=[]\n","    np.random.shuffle(X_train)\n","    for batch_idx in tqdm(range(num_batches),desc=('Epoch #%d' % epoch), leave=False):\n","        # Get the next set of real images to be used in this iteration\n","        images = X_train[batch_idx*BATCH_SIZE : (batch_idx+1)*BATCH_SIZE]\n","\n","        noise_data = generate_noise(BATCH_SIZE, 100)\n","        generated_images = generator.predict(noise_data)\n","\n","        # Train on soft labels (add noise to labels as well)\n","        noise_prop = 0.05 # Randomly flip 5% of labels\n","\n","        # Prepare labels for real data\n","        true_labels = np.zeros((BATCH_SIZE, 1)) + np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n","        flipped_idx = np.random.choice(np.arange(len(true_labels)), size=int(noise_prop*len(true_labels)))\n","        true_labels[flipped_idx] = 1 - true_labels[flipped_idx]\n","\n","        # Train discriminator on real data\n","        d_loss_true = discriminator.train_on_batch(images, true_labels)\n","        discriminator_true_loss.append(d_loss_true)\n","        \n","        # Prepare labels for generated data\n","        gene_labels = np.ones((BATCH_SIZE, 1)) - np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n","        flipped_idx = np.random.choice(np.arange(len(gene_labels)), size=int(noise_prop*len(gene_labels)))\n","        gene_labels[flipped_idx] = 1 - gene_labels[flipped_idx]\n","\n","        # Train discriminator on generated data\n","        d_loss_gene = discriminator.train_on_batch(generated_images, gene_labels)\n","        discriminator_gene_loss.append(d_loss_gene)\n","\n","        # Train generator\n","        noise_data = generate_noise(BATCH_SIZE, 100)\n","        g_loss = gan.train_on_batch(noise_data, np.zeros((BATCH_SIZE, 1)))\n","        generator_loss.append(g_loss)\n","       \n","    \n","    discriminator_true_loss=np.array(discriminator_true_loss).mean(axis=0)\n","    discriminator_gene_loss=np.array(discriminator_gene_loss).mean(axis=0)\n","    \n","    d_loss = 0.5 * (discriminator_true_loss[0]+discriminator_gene_loss[0])\n","    g_loss=np.array(generator_loss).mean(axis=0)\n","    \n","    logs['d_loss'].append(d_loss)\n","    logs['d_true_loss'].append(discriminator_true_loss[0])\n","    logs['d_gene_loss'].append(discriminator_gene_loss[0])\n","    logs['g_loss'].append(g_loss)\n","    \n","    \n","    # Test discriminator on test data from Cifat10\n","    discriminator_true_val_loss=[]\n","    discriminator_gene_val_loss=[]\n","    for k in tqdm(range(int(X_test.shape[0] // BATCH_SIZE )),desc=('Epoch (test) #%d' % epoch), leave=False):\n","        imgs=X_test[k*BATCH_SIZE : (k+1)*BATCH_SIZE]\n","        d_val_loss = discriminator.test_on_batch(imgs, np.zeros((BATCH_SIZE, 1)))\n","        discriminator_true_val_loss.append(d_val_loss)\n","        \n","        noise_data = generate_noise(BATCH_SIZE, 100)\n","        generated_images = generator.predict(noise_data)\n","        d_gene_loss = discriminator.test_on_batch(generated_images, np.ones((BATCH_SIZE, 1)))\n","        discriminator_gene_val_loss.append(d_gene_loss)\n","    discriminator_true_val_loss=np.array(discriminator_true_val_loss).mean(axis=0)\n","    discriminator_gene_val_loss=np.array(discriminator_gene_val_loss).mean(axis=0)\n","    d_true_val_loss, d_true_val_acc  = discriminator_true_val_loss\n","    d_gene_val_loss, d_gene_val_acc  = discriminator_gene_val_loss\n","    d_val_loss=0.5*(d_true_val_loss+d_gene_val_loss)\n","    \n","    logs_val['d_val_loss'].append(d_val_loss)\n","    logs_val['d_true_val_loss'].append(d_true_val_loss)\n","    logs_val['d_gene_val_loss'].append(d_gene_val_loss)\n","    logs_val['d_true_val_acc'].append(d_true_val_acc)\n","    logs_val['d_gene_val_acc'].append(d_gene_val_acc)\n","    \n","    \n","    print (\"%d [D loss: %f ] [G loss: %f]\" % (epoch, d_loss, g_loss))\n","    print (\"%d [D val_loss: %f, val_acc.real: %.2f%%, val_acc.gen: %.2f%%]\" % (epoch, d_val_loss, 100*d_true_val_acc, 100*d_gene_val_acc))\n","    \n","    row_dict = OrderedDict({'epoch': list(range(initial_epoch,epoch+1))})\n","    row_dict.update((key, logs[key]) for key in logs.keys())\n","    row_dict.update((key, logs_val[key]) for key in logs_val.keys())\n","    df=pd.DataFrame.from_dict(row_dict)\n","    \n","    df.to_csv(os.path.join(SAVE_DIR,'logs.csv'),index=False)\n","    \n","    if epoch%SAVE_INTERVAL==0 or epoch==1:\n","        show_imgs(epoch,SAVE_DIR)"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"metadata":{"id":"aflMahbKXGq4","colab_type":"code","colab":{}},"cell_type":"code","source":["discriminator.save_weights(os.path.join(SAVE_DIR,'discriminator.h5'))\n","gan.save_weights(os.path.join('gan.h5'))\n","generator.save_weights(os.path.join('generator.h5'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"e672T4h_XLQg","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}